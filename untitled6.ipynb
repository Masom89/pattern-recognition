{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOsfhQF0qzSYWz9KwEb3sC5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Masom89/pattern-recognition/blob/main/untitled6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        " \"cells\": [\n",
        "  {\n",
        "   \"attachments\": {},\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"# Demo Emotion Recognition: audio + video\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"attachments\": {},\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"## Libraries and parameters\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 1,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Utilities\\n\",\n",
        "    \"import os\\n\",\n",
        "    \"import subprocess\\n\",\n",
        "    \"import numpy as np\\n\",\n",
        "    \"import keras\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Audio and video manipulation\\n\",\n",
        "    \"import moviepy.editor as mp\\n\",\n",
        "    \"import cv2\\n\",\n",
        "    \"import librosa\\n\",\n",
        "    \"from joblib import load\\n\",\n",
        "    \"import tkinter as tk\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 2,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Labels dictionary\\n\",\n",
        "    \"emotions_tras = {1:1, 2:4, 3:5, 4:0, 5:3, 6:2, 7:6}\\n\",\n",
        "    \"emotions = {0:'angry', 1:'calm', 2:'disgust', 3:'fear', 4:'happy', 5:'sad', 6:'surprise'}\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Paths\\n\",\n",
        "    \"dataset_path = \\\"./Examples/\\\"\\n\",\n",
        "    \"haar_path = './../Other/haarcascade_frontalface_default.xml'\\n\",\n",
        "    \"parameters_path = './../Datasets/RAVDESS_audio/std_scaler.bin'\\n\",\n",
        "    \"models_video_path = \\\"./../Models/Video Stream/\\\"\\n\",\n",
        "    \"models_audio_path = \\\"./../Models/Audio Stream/\\\"\\n\",\n",
        "    \"vlc_path = \\\"C:/Program Files/VideoLAN/VLC/vlc.exe\\\" # to play the selected video (insert your own path to vlc.exe)\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Audio video parameters\\n\",\n",
        "    \"height_targ = 112\\n\",\n",
        "    \"width_targ = 112\\n\",\n",
        "    \"sr = 48000\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"attachments\": {},\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"## Select Clip\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 3,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"root= tk.Tk()\\n\",\n",
        "    \"\\n\",\n",
        "    \"canvas1 = tk.Canvas(root, width=400, height=300, relief='raised')\\n\",\n",
        "    \"canvas1.pack()\\n\",\n",
        "    \"\\n\",\n",
        "    \"label1 = tk.Label(root, text='Select clip to analize')\\n\",\n",
        "    \"label1.config(font=('helvetica', 16))\\n\",\n",
        "    \"canvas1.create_window(200, 25, window=label1)\\n\",\n",
        "    \"\\n\",\n",
        "    \"label2 = tk.Label(root, text='Number from 0 to 6:')\\n\",\n",
        "    \"label2.config(font=('helvetica', 11))\\n\",\n",
        "    \"canvas1.create_window(200, 100, window=label2)\\n\",\n",
        "    \"\\n\",\n",
        "    \"def display_text():\\n\",\n",
        "    \"   global example\\n\",\n",
        "    \"   example = int(example.get())\\n\",\n",
        "    \"   root.destroy\\n\",\n",
        "    \"\\n\",\n",
        "    \"example = tk.Entry(root)\\n\",\n",
        "    \"example.pack()\\n\",\n",
        "    \"canvas1.create_window(200, 140, window=example)\\n\",\n",
        "    \"\\n\",\n",
        "    \"    \\n\",\n",
        "    \"button1 = tk.Button(text='Select', command=lambda: [display_text(), root.destroy()], font=('helvetica', 12, 'bold'))\\n\",\n",
        "    \"canvas1.create_window(200, 180, window=button1)\\n\",\n",
        "    \"\\n\",\n",
        "    \"root.mainloop()\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 4,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"fn = os.listdir(dataset_path)\\n\",\n",
        "    \"filename = dataset_path + fn[example]\\n\",\n",
        "    \"label = emotions_tras[int(fn[example].split('-')[2]) - 1] # trasposition of the emotions\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 5,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"player = subprocess.call([vlc_path, filename, '--play-and-exit'])\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"attachments\": {},\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"id\": \"3d4a2239\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"## Data preparation\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"attachments\": {},\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"### Video\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 6,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [\n",
        "    {\n",
        "     \"name\": \"stdout\",\n",
        "     \"output_type\": \"stream\",\n",
        "     \"text\": [\n",
        "      \"shape frames: (32, 112, 112)\\n\"\n",
        "     ]\n",
        "    }\n",
        "   ],\n",
        "   \"source\": [\n",
        "    \"cap = cv2.VideoCapture(filename)\\n\",\n",
        "    \"haar_cascade = cv2.CascadeClassifier(haar_path)\\n\",\n",
        "    \"frames = []\\n\",\n",
        "    \"count = 0\\n\",\n",
        "    \"skip = 3\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Loop through all frames\\n\",\n",
        "    \"while True:\\n\",\n",
        "    \"    # Capture frame\\n\",\n",
        "    \"    ret, frame = cap.read()\\n\",\n",
        "    \"    if (count % skip == 0 and count > 20):\\n\",\n",
        "    \"        if not ret:\\n\",\n",
        "    \"            break\\n\",\n",
        "    \"        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\\n\",\n",
        "    \"        # detect and crop face\\n\",\n",
        "    \"        faces = haar_cascade.detectMultiScale(frame, scaleFactor=1.12, minNeighbors=9)\\n\",\n",
        "    \"        if len(faces) != 1:\\n\",\n",
        "    \"            continue\\n\",\n",
        "    \"        for (x, y, w, h) in faces:\\n\",\n",
        "    \"            face = frame[y:y + h, x:x + w]\\n\",\n",
        "    \"\\n\",\n",
        "    \"        face = cv2.resize(face, (height_targ+10, width_targ+10))\\n\",\n",
        "    \"        face = face[5:-5, 5:-5]\\n\",\n",
        "    \"        face = face/255.\\n\",\n",
        "    \"        frames.append(face)\\n\",\n",
        "    \"    count += 1\\n\",\n",
        "    \"\\n\",\n",
        "    \"frames = np.array(frames)\\n\",\n",
        "    \"num_frames = len(frames)\\n\",\n",
        "    \"labels = [label] * num_frames\\n\",\n",
        "    \"print('shape frames:', frames.shape)\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"attachments\": {},\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"### Audio\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 7,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"audiofile = mp.AudioFileClip(filename).set_fps(sr)\\n\",\n",
        "    \"audio = audiofile.to_soundarray()\\n\",\n",
        "    \"audio = audio[int(sr/2):int(sr/2 + sr*3)]\\n\",\n",
        "    \"audio = np.array([elem[0] for elem in audio])\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 8,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [\n",
        "    {\n",
        "     \"data\": {\n",
        "      \"text/plain\": [\n",
        "       \"(1, 128, 282, 1)\"\n",
        "      ]\n",
        "     },\n",
        "     \"execution_count\": 8,\n",
        "     \"metadata\": {},\n",
        "     \"output_type\": \"execute_result\"\n",
        "    }\n",
        "   ],\n",
        "   \"source\": [\n",
        "    \"mel = librosa.power_to_db(librosa.feature.melspectrogram(audio, sr = 48000, n_fft = 1024, n_mels = 128, fmin = 50, fmax = 24000)) \\n\",\n",
        "    \"\\n\",\n",
        "    \"scaler = load(parameters_path)\\n\",\n",
        "    \"mel = scaler.transform(mel)\\n\",\n",
        "    \"\\n\",\n",
        "    \"mel = np.expand_dims(mel, axis = 2)\\n\",\n",
        "    \"mel = np.expand_dims(mel, axis = 0)\\n\",\n",
        "    \"mel.shape\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"attachments\": {},\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"## Load models\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"attachments\": {},\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"### Video\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 9,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"models_list = os.listdir(models_video_path)\\n\",\n",
        "    \"\\n\",\n",
        "    \"acc = [float(model.split('[')[1].split(']')[0]) for model in models_list]\\n\",\n",
        "    \"idx = acc.index(max(acc))                                                       # index of best model\\n\",\n",
        "    \"\\n\",\n",
        "    \"model_video = keras.models.load_model(models_video_path + models_list[idx])\\n\",\n",
        "    \"# model_video.summary()\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"attachments\": {},\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"### Audio\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 10,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"models_list = os.listdir(models_audio_path)\\n\",\n",
        "    \"model_audio = keras.models.load_model(models_audio_path + models_list[0])\\n\",\n",
        "    \"# model_audio.summary()\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"attachments\": {},\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"## Predictions\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"attachments\": {},\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"### Video\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 11,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [\n",
        "    {\n",
        "     \"name\": \"stdout\",\n",
        "     \"output_type\": \"stream\",\n",
        "     \"text\": [\n",
        "      \"1/1 [==============================] - 2s 2s/step\\n\"\n",
        "     ]\n",
        "    },\n",
        "    {\n",
        "     \"data\": {\n",
        "      \"text/plain\": [\n",
        "       \"array([3.90350557e-04, 2.60067428e-03, 5.59035325e-05, 1.19173186e-04,\\n\",\n",
        "       \"       9.39146042e-01, 6.43615067e-06, 5.76814897e-02], dtype=float32)\"\n",
        "      ]\n",
        "     },\n",
        "     \"execution_count\": 11,\n",
        "     \"metadata\": {},\n",
        "     \"output_type\": \"execute_result\"\n",
        "    }\n",
        "   ],\n",
        "   \"source\": [\n",
        "    \"pred = model_video.predict(frames)\\n\",\n",
        "    \"pred_video = np.mean(pred, axis=0)\\n\",\n",
        "    \"pred_video\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"attachments\": {},\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"### Audio\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 12,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [\n",
        "    {\n",
        "     \"name\": \"stdout\",\n",
        "     \"output_type\": \"stream\",\n",
        "     \"text\": [\n",
        "      \"1/1 [==============================] - 0s 275ms/step\\n\"\n",
        "     ]\n",
        "    },\n",
        "    {\n",
        "     \"data\": {\n",
        "      \"text/plain\": [\n",
        "       \"array([2.4040800e-02, 5.5525964e-04, 7.1970987e-01, 1.8299127e-01,\\n\",\n",
        "       \"       3.4310304e-02, 3.6364559e-02, 2.0280003e-03], dtype=float32)\"\n",
        "      ]\n",
        "     },\n",
        "     \"execution_count\": 12,\n",
        "     \"metadata\": {},\n",
        "     \"output_type\": \"execute_result\"\n",
        "    }\n",
        "   ],\n",
        "   \"source\": [\n",
        "    \"pred = model_audio.predict(mel)\\n\",\n",
        "    \"pred_audio = np.mean(pred, axis=0)\\n\",\n",
        "    \"pred_audio\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"attachments\": {},\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"### Global\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 13,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"pred_global = pred_video + pred_audio # mean\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 14,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [\n",
        "    {\n",
        "     \"name\": \"stdout\",\n",
        "     \"output_type\": \"stream\",\n",
        "     \"text\": [\n",
        "      \"Video prediction:\\t happy\\n\",\n",
        "      \"Audio prediction:\\t disgust\\n\",\n",
        "      \"Global prediction:\\t happy\\n\",\n",
        "      \"Ground truth:\\t\\t happy\\n\"\n",
        "     ]\n",
        "    }\n",
        "   ],\n",
        "   \"source\": [\n",
        "    \"print('Video prediction:\\\\t', emotions[pred_video.argmax()])\\n\",\n",
        "    \"print('Audio prediction:\\\\t', emotions[pred_audio.argmax()])\\n\",\n",
        "    \"print('Global prediction:\\\\t', emotions[pred_global.argmax()])\\n\",\n",
        "    \"\\n\",\n",
        "    \"print('Ground truth:\\\\t\\\\t', emotions[label])\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 15,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Print Results\\n\",\n",
        "    \"root = tk.Tk()\\n\",\n",
        "    \"\\n\",\n",
        "    \"# root window title and dimension\\n\",\n",
        "    \"root.title(\\\"Results predictions\\\")\\n\",\n",
        "    \"\\n\",\n",
        "    \"canvas1 = tk.Canvas(root, width=400, height=300, relief='raised')\\n\",\n",
        "    \"canvas1.pack()\\n\",\n",
        "    \"\\n\",\n",
        "    \"label1 = tk.Label(root, text=f'Video prediction:\\\\t{emotions[pred_video.argmax()]}')\\n\",\n",
        "    \"label2 = tk.Label(root, text=f'Audio prediction:\\\\t{emotions[pred_audio.argmax()]}')\\n\",\n",
        "    \"label3 = tk.Label(root, text=f'Global prediction:\\\\t{emotions[pred_global.argmax()]}')\\n\",\n",
        "    \"label4 = tk.Label(root, text=f'Ground truth:\\\\t{emotions[label]}')\\n\",\n",
        "    \"\\n\",\n",
        "    \"label1.config(font=('helvetica', 14))\\n\",\n",
        "    \"label2.config(font=('helvetica', 14))\\n\",\n",
        "    \"label3.config(font=('helvetica', 14))\\n\",\n",
        "    \"label4.config(font=('helvetica', 14), fg='gray')\\n\",\n",
        "    \"\\n\",\n",
        "    \"canvas1.create_window(20, 25, window=label1, anchor='w')\\n\",\n",
        "    \"canvas1.create_window(20, 50, window=label2, anchor='w')\\n\",\n",
        "    \"canvas1.create_window(20, 75, window=label3, anchor='w')\\n\",\n",
        "    \"canvas1.create_window(20, 120, window=label4, anchor='w')\\n\",\n",
        "    \"\\n\",\n",
        "    \"button1 = tk.Button(text='Close', command=lambda: root.destroy(), font=('helvetica', 12, 'bold'))\\n\",\n",
        "    \"canvas1.create_window(200, 200, window=button1)\\n\",\n",
        "    \"\\n\",\n",
        "    \"root.mainloop()\"\n",
        "   ]\n",
        "  }\n",
        " ],\n",
        " \"metadata\": {\n",
        "  \"kernelspec\": {\n",
        "   \"display_name\": \"base\",\n",
        "   \"language\": \"python\",\n",
        "   \"name\": \"python3\"\n",
        "  },\n",
        "  \"language_info\": {\n",
        "   \"codemirror_mode\": {\n",
        "    \"name\": \"ipython\",\n",
        "    \"version\": 3\n",
        "   },\n",
        "   \"file_extension\": \".py\",\n",
        "   \"mimetype\": \"text/x-python\",\n",
        "   \"name\": \"python\",\n",
        "   \"nbconvert_exporter\": \"python\",\n",
        "   \"pygments_lexer\": \"ipython3\",\n",
        "   \"version\": \"3.9.7\"\n",
        "  },\n",
        "  \"orig_nbformat\": 4,\n",
        "  \"vscode\": {\n",
        "   \"interpreter\": {\n",
        "    \"hash\": \"ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186\"\n",
        "   }\n",
        "  }\n",
        " },\n",
        " \"nbformat\": 4,\n",
        " \"nbformat_minor\": 2\n",
        "}"
      ],
      "metadata": {
        "id": "WsjaAQot8v-S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}